{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCNER assigment for Data Science by Irma Harms and Maaike Keurhorst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decription of project:\n",
    "\n",
    "This study investigates which combination of methods works best for recommending a conference to a researcher given the title of this new research paper. The methods were formed by combining dimensionality reduction techniques (Term Frequency and Term Frequency-Inverse Document Frequency) with classifiers (Naive Bayes, K-Nearest Neighbors, Linear Support Vector Machine), giving us six combinations. The results showed that TF-IDF Naïve Bayes was the fastest and TF-IDF Linear Support Vector Machine was the best performing. Overall, the Naïve Bayes methods did perform just a bit less than the others, but might be a better classifier for bigger data sets due to its speed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All imports\n",
    "\n",
    "To keep everything clear and to avoid redundancy in imports, we do them all here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions preprocessing\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Functions feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Functions for classification\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions for getting the data and data preprocessing\n",
    "\n",
    "We save the data in pandas for ease of use. The txt files gotten have first been converted to excel before used in the code. \n",
    "\n",
    "\n",
    "For the preprocessing we take the following steps:\n",
    "\n",
    "- Stopword removal\n",
    "- Lemmetazation\n",
    "- Tokenization\n",
    "- Lowercase\n",
    "- Punctuation and character removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a pandas dataframe\n",
    "def getData(textfile):\n",
    "    df = pd.read_excel(textfile)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the preprocessing steps as mentioned before. Returns tokens.\n",
    "def preprocessing(title, nlp):\n",
    "    # Tokenization\n",
    "    title = nlp(str(title))\n",
    "    tokens = [token.lemma_ for token in title]\n",
    "    \n",
    "    # Punctuation, stopword and space removal\n",
    "    tokens = [token for token in tokens if not nlp.vocab[token].is_punct | nlp.vocab[token].is_space | nlp.vocab[token].is_stop]\n",
    "    \n",
    "    # Lowercase\n",
    "    tokens = [token for token in tokens if token.lower()]\n",
    "    \n",
    "    # Character removal: Check if it at least has some letters, otherwise remove\n",
    "    tokens = [token for token in tokens if token.islower()]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions for feature extraction\n",
    "\n",
    "This is combined in the pipeline together with the classifier, so we only need a function to combine the tokens back into one text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_to_text(corpus):\n",
    "    space = \" \"\n",
    "    return [space.join(lst) for lst in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions for classification\n",
    "\n",
    "All classifiers use the predict function to make the pipeline and make the actual prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, x, y, prepros):\n",
    "    if prepros == 'tfidf':\n",
    "        print('tfidf')\n",
    "        pipeline = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', clf),]) \n",
    "    else:\n",
    "        print('bow')\n",
    "        pipeline = Pipeline([('vect', CountVectorizer()),('clf', clf),]) \n",
    "\n",
    "    return cross_val_predict(pipeline, x, y, cv=3, n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine\n",
    "def svm_linear(x, y, prepros):\n",
    "    \n",
    "    # The classifier\n",
    "    clf = svm.SVC(kernel = 'linear')\n",
    "    \n",
    "    return predict(clf, x, y, prepros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinominal bayes\n",
    "def bayes(x, y, prepros):\n",
    "    \n",
    "    # The classifier\n",
    "    clf = MultinomialNB()\n",
    "\n",
    "    return predict(clf, x, y, prepros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbors\n",
    "def k_nearest_neigbours(x, y, prepros, k):\n",
    "    \n",
    "    # The classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    return predict(clf, x, y, prepros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulation\n",
    "\n",
    "Here is the method we can call for evauating our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(real, pred):\n",
    "    precision, recall, fscore, support = score(real, pred, average='macro')\n",
    "\n",
    "    print(pd.crosstab(real, pred, rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "    print(' ')\n",
    "    print('F1 score:', f1_score(real, pred, average='macro'))\n",
    "    print('Recall:', recall_score(real, pred, average='macro'))\n",
    "    print('Accuracy:', accuracy_score(real, pred))\n",
    "    print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling all functions\n",
    "Here we can call all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data\n",
    "test_gt = getData('TestGroundTruth.xlsx')\n",
    "test = getData('Test.xlsx')\n",
    "train = getData('Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "nlp = en_core_web_sm.load()\n",
    "tokens_test = [preprocessing(text, nlp) for text in test['Title']]\n",
    "tokens_train = [preprocessing(text, nlp) for text in train['Title']]\n",
    "text_train = return_to_text(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   13.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   13.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Training of bow\n",
    "svm_linear_tfidf_pred = svm_linear(text_train, train['Conference'], 'tfidf')\n",
    "bayes_tfidf_pred = bayes(text_train, train['Conference'], 'tfidf')\n",
    "knn_tfidf_pred = k_nearest_neigbours(text_train, train['Conference'], 'tfidf', 1)\n",
    "\n",
    "svm_linear_bow_pred = svm_linear(text_train, train['Conference'], 'bow')\n",
    "bayes_bow_pred = bayes(text_train, train['Conference'], 'bow')\n",
    "knn_bow_pred = k_nearest_neigbours(text_train, train['Conference'], 'bow', 1)\n",
    "\n",
    "\n",
    "# Used for finding the best k value. \n",
    "# for i in range(1, 8):\n",
    "#     knn_tfidf_pred = k_nearest_neigbours(text_train, train['Conference'], 'bow', i)\n",
    "#     print('(', i, ',', f1_score(train['Conference'], knn_tfidf_pred, average = 'micro'), ')')\n",
    "    \n",
    "# for i in range(1,11):\n",
    "#     knn_bow_pred = k_nearest_neigbours(text_train, train['Conference'], 'tfidf', i)\n",
    "#     print('(', i, ',', f1_score(train['Conference'], knn_bow_pred, average = 'micro'), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_linear_bow\n",
      "Predicted  INFOCOM  ISCAS  SIGGRAPH  VLDB   WWW    All\n",
      "Actual                                                \n",
      "INFOCOM       2792    321        34  1209   125   4481\n",
      "ISCAS          628   5924       169   721    72   7514\n",
      "SIGGRAPH       170    312      1730   389    77   2678\n",
      "VLDB           451    149        33  2848   197   3678\n",
      "WWW            352    131        74   439  2296   3292\n",
      "All           4393   6837      2040  5606  2767  21643\n",
      " \n",
      "F1 score: 0.7119224302630673\n",
      "Recall: 0.7058513840314863\n",
      "Accuracy: 0.7203252783810008\n",
      "Precision: 0.7375728679771367\n",
      " \n",
      " \n",
      "bayes_bow\n",
      "Predicted  INFOCOM  ISCAS  SIGGRAPH  VLDB   WWW    All\n",
      "Actual                                                \n",
      "INFOCOM       2753   1313        43   153   219   4481\n",
      "ISCAS          294   6893       155    67   105   7514\n",
      "SIGGRAPH        83    467      1914    65   149   2678\n",
      "VLDB           315   1524        81  1286   472   3678\n",
      "WWW            258    199        61   223  2551   3292\n",
      "All           3703  10396      2254  1794  3496  21643\n",
      " \n",
      "F1 score: 0.6880638379319313\n",
      "Recall: 0.6741987906109144\n",
      "Accuracy: 0.711407845492769\n",
      "Precision: 0.7404353508774533\n",
      " \n",
      " \n",
      "knn_bow\n",
      "Predicted  INFOCOM  ISCAS  SIGGRAPH  VLDB   WWW    All\n",
      "Actual                                                \n",
      "INFOCOM       1938   1153       343   967    80   4481\n",
      "ISCAS         1208   3965       343  1894   104   7514\n",
      "SIGGRAPH       346    788       779   707    58   2678\n",
      "VLDB           458   1146       394  1578   102   3678\n",
      "WWW            486    452       111  1228  1015   3292\n",
      "All           4436   7504      1970  6374  1359  21643\n",
      " \n",
      "F1 score: 0.4096677893663502\n",
      "Recall: 0.3976847718299619\n",
      "Accuracy: 0.42854502610543826\n",
      "Precision: 0.47102747042799703\n",
      " \n",
      " \n",
      "svm_linear_tfidf\n",
      "Predicted  INFOCOM  ISCAS  SIGGRAPH  VLDB   WWW    All\n",
      "Actual                                                \n",
      "INFOCOM       2790    506        37  1023   125   4481\n",
      "ISCAS          416   6377       134   539    48   7514\n",
      "SIGGRAPH       124    335      1800   343    76   2678\n",
      "VLDB           402    345        48  2632   251   3678\n",
      "WWW            319    162        59   450  2302   3292\n",
      "All           4051   7725      2078  4987  2802  21643\n",
      " \n",
      "F1 score: 0.7221754505664248\n",
      "Recall: 0.711666399032112\n",
      "Accuracy: 0.7346948204962344\n",
      "Precision: 0.7459532417935899\n",
      " \n",
      " \n",
      "bayes_tfidf\n",
      "Predicted  INFOCOM  ISCAS  SIGGRAPH  VLDB   WWW    All\n",
      "Actual                                                \n",
      "INFOCOM       2593   1623        20   110   135   4481\n",
      "ISCAS          211   7181        42    34    46   7514\n",
      "SIGGRAPH        96    886      1504    47   145   2678\n",
      "VLDB           323   1718        44  1212   381   3678\n",
      "WWW            328    331        31   237  2365   3292\n",
      "All           3551  11739      1641  1640  3072  21643\n",
      " \n",
      "F1 score: 0.6574280421207052\n",
      "Recall: 0.6287793050859058\n",
      "Accuracy: 0.6863651065009472\n",
      "Precision: 0.753466786732355\n",
      " \n",
      " \n",
      "knn_tfidf\n",
      "Predicted  INFOCOM  ISCAS  SIGGRAPH  VLDB   WWW    All\n",
      "Actual                                                \n",
      "INFOCOM       1688   1465       642   563   123   4481\n",
      "ISCAS          466   5008      1486   491    63   7514\n",
      "SIGGRAPH       125   1134      1183   163    73   2678\n",
      "VLDB           483   1043       411  1538   203   3678\n",
      "WWW            259   1226       634   534   639   3292\n",
      "All           3021   9876      4356  3289  1101  21643\n",
      " \n",
      "F1 score: 0.4189540184739785\n",
      "Recall: 0.4194414785017987\n",
      "Accuracy: 0.4646305964977129\n",
      "Precision: 0.47708470161841043\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# put all the predictions in a dict.\n",
    "predictions = {'svm_linear_bow': svm_linear_bow_pred, 'bayes_bow': bayes_bow_pred, \n",
    "               'knn_bow': knn_bow_pred, 'svm_linear_tfidf': svm_linear_tfidf_pred, \n",
    "                'bayes_tfidf': bayes_tfidf_pred, 'knn_tfidf': knn_tfidf_pred}\n",
    "\n",
    "# Print all scores\n",
    "for each in predictions:\n",
    "    print(each)\n",
    "    get_scores(train['Conference'], predictions[each])\n",
    "    print(' ')\n",
    "    print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
